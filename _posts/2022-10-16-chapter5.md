layout single
title: "Chapter 5"

## 주제

감독되지 않은 데이터 압축을 위한 주성분 분석

클래스 분리성을 최대화하기 위한 지도 차원 축소 기법으로서의 선형 판별 분석

데이터 시각화를 위한 비선형 차원 축소 기술 및 t-분산 확률적 이웃 임베딩에 대한 간략한 개요

## Unsupervised dimensionality reduction via principal component analysis!

### 주성분 분석을 통한 비지도 차원 축소

다른 특징 추출 기술을 사용하여 데이터 세트의 특징 수를 줄일 수 있음. 

특성 선택과 특성 추출의 차이점

순차 역방향 선택과 같은 특성 선택 알고리즘을 사용할 때 원래 특성을 유지

특성 추출을 사용하여 데이터를 새로운 특성 공간으로 변환하거나 투영

차원 축소의 맥락에서 특징 추출은 대부분의 관련 정보를 유지하기 위한 목적으로 데이터 압축에 대한 접근 방식으로 이해 가능하다



## PCA : principal component analysis

PCA는 기능 간의 상관 관계를 기반으로 데이터의 패턴을 식별하는 데 도움이 된다. 

- PCA는 고차원 데이터에서 최대 분산 방향을 찾는 것을 목표로 하고 데이터를 원래 데이터와 같거나 더 적은 차원을 가진 새로운 부분 공간에 투영한다.

  

새 부분 공간의 직교 축(주성분)은 그림 5.1과 같이 새 기능 축이 서로 직교한다는 제약 조건이 주어지면 최대 분산 방향으로 해석될 수 있다.



  ![그림입니다. 원본 그림의 이름: CLP0000295c164b.bmp 원본 그림의 크기: 가로 462pixel, 세로 380pixel](file:///C:\Users\Juns\AppData\Local\Temp\Hnc\BinData\EMB0000295c1ea6.bmp)  

​    

차원 축소를 위해 PCA를 사용하는 경우 d×k 차원 변환 행렬 W를 구성하여 훈련 예제 x의 특징 벡터를 원래의 d차원 특징 공간. 예를 들어, 프로세스는 다음과 같습니다. 특징 벡터 x가 있다고 가정한다.







\\
