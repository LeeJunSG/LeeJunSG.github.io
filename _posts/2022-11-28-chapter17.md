layout single title: "Chapter 17"


17장


### Starting with autoencoders

자동 인코더 :  훈련 데이터를 압축 및 압축 해제할 수 있다.

자동 인코더는 함께 연결된 두 개의 네트워크, 즉 인코더 네트워크와 디코더 네트워크로 구성되며, 인코더 네트워크는 예제 x와 연관된 d차원 입력 피쳐 벡터를 수신하고 이를 p차원 벡터로 인코딩한다. 

- 인코더의 역할은 함수 z = f(x)를 모델링하는 방법을 배움

 인코딩된 벡터 z는 잠재 벡터 또는 잠재 피쳐 표현이라고도 한다. 일반적으로 잠재 벡터의 차원성은 입력 예제의 차원보다 작다. 즉, p < d. 따라서, 인코더는 데이터 압축 기능으로 작용한다고 말할 수 있다. 그런 다음 디코더는 저차원 잠재 벡터 z에서 𝒙를 압축 해제하는데, 여기서 우리는 디코더를 함수로 생각할 수 있다. 간단한 자동 인코더 아키텍처는 그림과 같이 표현할 수 있다. 즉, 여기서 인코더와 디코더 부분은 각각 완전히 연결된 하나의 레이어로만 구성된다.

![그림](/image/image-20221127033144657.png)

### Generative models for synthesizing new data

자동 인코더는 결정론적 모델이며, 이는 입력 x가 주어지면 자동 인코더가 압축된 버전에서 입력을 저차원 공간에서 재구성할 수 있음을 의미한다. 따라서 압축된 표현의 변환을 통해 입력을 재구성하는 것 외에는 새로운 데이터를 생성할 수 없다.
반면에 생성 모델은 임의의 벡터 z(잠재 표현에 대응)로부터 새로운 예인 𝒙'를 생성할 수 있습니다. 생성 모델의 개략적인 표현은 다음 그림에 나와 있습니다. 랜덤 벡터 z는 완전히 알려진 특성을 가진 분포에서 나오기 때문에 이러한 분포에서 쉽게 표본을 추출할 수 있다. 

![그림](/image/image-20221127033216428.png)

### Generating new samples with GANs



GAN은 먼저 샘플링된 랜덤 벡터 z를 수신하고 출력 이미지 x를 생성하는 네트워크가 있다고 가정한다. 이 네트워크 생성기를 (G)라고 부르고 생성된 출력을 참조하기 위해 표기법을 사용한다. 목표로 얼굴 이미지, 건물 이미지, 동물 이미지 또는 MNIST와 같은 손으로 쓴 숫자와 같은 일부 이미지를 생성하는 것이라고 가정한다.

랜덤 가중치를 사용하여 이 네트워크를 초기화할 것이다. 따라서 이러한 가중치를 조정하기 전에 첫 번째 출력 영상은 흰색 노이즈처럼 보인다. 이제 이미지의 품질을 평가할 수 있는 기능이 있다면, 해당 기능의 피드백을 사용하여 생성된 이미지의 품질을 향상시키기 위해 가중치를 조정하는 방법을 생성기 네트워크에 알려줄 수 있다. 이러한 방식으로, 해당 평가자 기능의 피드백을 기반으로 제너레이터를 훈련하여 제너레이터가 현실적으로 보이는 이미지를 생성하기 위해 출력을 개선하는 방법을 배울 수 있다.

이전 단락에서 설명한 것처럼 평가자 기능은 이미지 생성 작업을 매우 쉽게 만들 수 있지만, 문제는 이미지의 품질을 평가하기 위한 그러한 보편적인 기능이 존재하는지 그리고 만약 그렇다면, 어떻게 정의 할 수 있는 지는 모른다.

사람은 네트워크의 출력을 관찰할 때 출력 이미지의 품질을 쉽게 평가할 수 있다. 이제, 뇌가 합성된 이미지의 품질을 평가할 수 있다면, 같은 일을 할 수 있도록 NN 모델을 설계할 수 있을까? 라는 질문이 GAN의 구성에 대한 아이디어이다.

그림에 나온 것처럼, GAN 모델은 실제 이미지 x에서 합성된 이미지인 𝒙̃를 감지하는 방법을 배우는 분류기인 판별기(D)라는 추가 NN으로 구성된다.


![그림](/image/image-20221127033311523.png)

### Understanding the loss functions of the generator and discriminator networks in a GAN model

생성기가 사실적인 이미지를 합성하기를 원하므로, 우리는 출력이 판별기에 의해 실제로 분류되지 않을 때 생성기에 불이익을 주고자, 제너레이터의 손실 함수를 계산할 때 제너레이터의 출력에 대한 실측값 레이블을 1로 가정한다.

이 모든 것을 종합하면, 다음 그림은 단순 GAN 모델의 개별 단계는 다음과 같다.

![그림](/image/image-20221127033358278.png)

### Implementing the generator and the discriminator networks

우리는 그림에 나온 것처럼 하나 이상의 숨겨진 계층이 있는 두 개의 완전 연결 네트워크로서 발전기와 판별기를 가진 첫 번째 GAN 모델의 구현은 다음과 같다.

![그림](/image/image-20221127033424409.png)



### Transposed convolution

전치된 컨볼루션 연산의 이해 : 

- 크기가 nxn인 입력 피쳐 맵이 있다고 가정한다. 

- 특정 패딩 및 스트라이드 매개 변수가 있는 2D 컨볼루션 연산을 이 nxn 입력에 적용하여 크기가 mxm인 출력 피쳐 맵을 생성합니다. 

- 입력과 출력 사이의 연결 패턴을 유지하면서 이 mxm 출력 피처 맵에서 초기 치수 nxn의 피처 맵을 얻기 위해 다른 컨볼루션 연산을 어떻게 적용할 수 있는가 이다.

- nxn 입력 행렬의 모양만 복구되고 실제 행렬 값은 복구되지 않는다.

다음 그림은 전치된 컨볼루션이 수행하는 작업이다.

![그림](/image/image-20221127034029570.png)

전치 컨볼루션을 사용한 형상 맵 업샘플링은 입력 형상 맵의 요소 사이에 0을 삽입하여 작동한다. 위의 그림은 2×2의 스트라이드와 2×2의 커널 크기를 가진 4×4 크기의 입력에 전치 컨볼루션을 적용하는 예이다. 중앙에 있는 9x9 크기의 행렬은 입력 형상 맵에 이러한 0을 삽입한 후의 결과를 보여준다. 그런 다음 스트라이드가 1인 2x2 커널을 사용하여 일반 컨볼루션을 수행하면 크기가 8x8이 됩니다. 2의 스트라이드로 출력에 대해 정규 컨볼루션을 수행하여 원래 입력 크기와 동일한 4x4 크기의 출력 피쳐 맵을 생성함으로써 역방향을 확인할 수 있다.

![그림](/image/image-20221127034050681.png)

### Batch normalization

BatchNorm의 주요 아이디어 중 하나는 계층 입력을 정규화하고 훈련 중에 분포의 변화를 방지하여 더 빠르고 더 나은 수렴을 가능하게 하는 것이다.
BatchNorm은 계산된 통계량을 기반으로 기능의 작은 배치를 변환한다. 

BatchNorm은 다음과 같이 세 단계로 요약할 수 있다.

1. 각 미니 배치에 대한 순 입력의 평균과 표준 편차를 계산한다.
2. 배치의 모든 예제에 대한 순 입력을 표준화한다.
3. 크기 c(채널 수)의 두 가지 학습 가능한 매개 변수 벡터인 θ와 θ를 사용하여 정규화된 순 입력의 크기를 조정하고 이동한다.

![그림](/image/image-20221127034150369.png)

### Implementing the generator and discriminator

DCGAN 모델의 주요 구성 요소인 제너레이터 및 판별기 네트워크의 아키텍처는 다음 두 그림과 같다.

![그림](/image/image-20221127040210528.png)

![그림](/image/image-20221127040231331.png)

생성기는 크기가 100인 벡터 z를 입력으로 사용한다. 그런 다음 nn을 사용하여 일련의 전치 컨볼루션을 사용합니다.ConvTranspose2d()는 결과 피쳐 맵의 공간 차원이 28x28에 도달할 때까지 피쳐 맵을 업샘플링한다. 채널 수는 하나의 출력 필터만 사용하여 그레이스케일 영상을 생성하는 마지막 출력 레이어를 제외하고 각 합성곱 레이어 이후에 절반으로 감소합니다.  탄 활성화를 사용하는 마지막 기능을 제외하고, 각 트랜스포즈 컨볼루션 레이어는 배치Norm 및 누출 ReLU 활성화 기능이 뒤따른다. 이와 같은 생성기의 아키텍처는 그림에서 확인 할 수 있다. 

판별기는 4개의 컨볼루션 레이어를 통과하는 크기 1x28x28의 이미지를 수신한다. 처음 세 개의 컨볼루션 레이어는 형상 맵의 채널 수를 증가시키면서 공간 차원성을 4만큼 줄인다. 각 컨볼루션 레이어에는 배치 노름 및 누출 ReLU 활성화도 뒤따른다. 마지막 컨볼루션 레이어는 7x7 크기의 커널과 단일 필터를 사용하여 출력의 공간 차원을 1x1x1로 줄인다. 마지막으로, 합성곱 출력 뒤에 시그모이드 함수가 나타나며 1차원으로 압축된다.

