layout single
title: "Chapter 6"

## Streamlining workflows with pipelines

scikit-learn의 Pipeline 클래스에 대해 배웁니다. 이를 통해 임의의 수의 변환 단계를 포함하는 모델을 피팅하고 이를 적용하여 새로운 데이터에 대한 예측을 할 수 있습니다.



## Loading the Breast Cancer Wisconsin dataset

악성 및 양성 종양 세포의 569개 예를 포함하는 유방암 위스콘신 데이터 세트로 작업할 것이다. 데이터 세트의 처음 두 열은 각각 예제의 고유 ID 번호와 해당 진단(M = 악성, B = 양성)을 저장한다. 열 3-32에는 종양이 양성인지 악성인지 예측하는 모델을 구축하는 데 사용할 수 있는 세포 핵의 디지털화된 이미지에서 계산된 30개의 실제 값이 포함되어 있다.



## Combining transformers and estimators in a pipeline

 유방암 위스콘신 데이터세트의 기능은 다양한 척도로 측정되므로 로지스틱 회귀와 같은 선형 분류기에 제공하기 전에 위스콘신 유방암 데이터세트의 열을 표준화한다. 또한, 5장에서 소개된 차원 축소를 위한 특징 추출 기술인 PCA(주성분 분석)를 통해 초기 30차원의 데이터를 더 낮은 2차원 부분 공간으로 압축한다고 가정한다.

  ![그림입니다. 원본 그림의 이름: CLP0000295c0036.bmp 원본 그림의 크기: 가로 391pixel, 세로 225pixel](file:///C:\Users\Juns\AppData\Local\Temp\Hnc\BinData\EMB0000295c17c8.bmp)  



make_pipeline 함수는 임의의 수의 scikit-learn 변환기(fit 및 transform 방법을 입력으로 지원하는 객체)를 취한 다음 fit 및 predict 방법을 구현하는 scikit-learn 추정기를 사용합니다. 



앞의 코드 예제에서 두 개의 scikit-learn 변환기, StandardScaler 및 PCA와 LogisticRegression 추정기를 make_pipeline 함수에 대한 입력으로 제공했는데, 이 함수는 이러한 개체에서 scikit-learn Pipeline 개체를 구성합니다.



 scikit-learn 파이프라인을 개별 변환기 및 추정기를 둘러싼 메타 추정기 또는 래퍼로 생각할 수 있다. Pipeline의 fit 메소드를 호출하면 데이터는 추정기 객체(파이프라인의 최종 요소)에 도달할 때까지 이러한 중간 단계에서 fit 및 transform 호출을 통해 일련의 변환기로 전달됩니다. 그런 다음 추정기는 변환된 훈련 데이터에 맞춰진다.



앞의 코드 예제에서 pipe_lr 파이프라인에서 fit 메서드를 실행했을 때 StandardScaler

첫째 : 훈련 데이터에 대해 fit 및 transform 호출을 수행한다. 



둘째, 변환된 훈련 데이터는 파이프라인의 다음 개체인 PCA로 전달되었습니다. 

​	- PCA는 크기 조정된 입력 데이터에 대해 적합 및 변환을 실행하고 이를 파이프라인의 최종 요소인 추정기에 전달한다.

셋째 : LogisticRegression 추정기는 StandardScaler 및 PCA를 통해 변환을 거친 후 훈련 데이터에 적합하다.



파이프라인의 중간 단계 수에는 제한이 없다. 

예측 작업에 파이프라인을 사용하려면 마지막 파이프라인 요소가 추정기여야 한다.

파이프라인에서 fit을 호출하는 것과 유사하게 파이프라인의 마지막 단계가 추정기인 경우 파이프라인도 예측 메서드를 구현한다. 파이프라인 개체 인스턴스의 예측 호출에 데이터 세트를 공급하면 데이터는 변환 호출을 통해 중간 단계를 통과합니다. 마지막 단계에서 estimator 객체는 변환된 데이터에 대한 예측을 반환한다.

  ![그림입니다. 원본 그림의 이름: CLP0000295c0035.bmp 원본 그림의 크기: 가로 456pixel, 세로 305pixel](file:///C:\Users\Juns\AppData\Local\Temp\Hnc\BinData\EMB0000295c17a0.bmp)  

## The holdout method

기계 학습 모델의 일반화 성능을 추정하기 위한 고전적이고 대중적인 접근 방식은 홀드아웃 방법이다.



 홀드아웃 방법을 사용하여 초기 데이터 세트를 별도의 훈련 및 테스트 데이터 세트로 분할한다. 



훈련 데이터는 모델 훈련에 사용되고 테스트 데이터는 일반화 성능을 추정하는 데 사용됩니다. 그러나 일반적인 기계 학습 응용 프로그램에서 우리는 보이지 않는 데이터에 대한 예측을 위한 성능을 더욱 향상시키기 위해 다른 매개변수 설정을 조정하고 비교하는 데에도 관심이 많다.



이 프로세스를 모델 선택이라고 하며, 이름은 튜닝 매개변수(하이퍼 매개변수라고도 함)의 최적 값을 선택하려는 주어진 분류 문제를 나타냅니다. 그러나 모델을 선택하는 동안 동일한 테스트 데이터 세트를 계속해서 재사용하면 훈련 데이터의 일부가 되므로 모델이 과적합될 가능성이 높아진다.

​    

   

모델 선택에 홀드아웃 방법을 사용하는 더 좋은 방법은 데이터를 훈련 데이터 세트, 검증 데이터 세트 및 테스트 데이터 세트의 세 부분으로 분리하는 것입니다. 

훈련 데이터 세트는 다양한 모델을 맞추는 데 사용되며 검증 데이터 세트의 성능은 모델 선택에 사용됩니다. 

훈련 및 모델 선택 단계에서 모델이 이전에 본 적이 없는 테스트 데이터 세트를 갖는 이점은 새로운 데이터로 일반화하는 능력에 대해 덜 편향된 추정치를 얻을 수 있다는 것입니다. 



![그림입니다. 원본 그림의 이름: CLP0000295c0037.bmp 원본 그림의 크기: 가로 387pixel, 세로 255pixel](file:///C:\Users\Juns\AppData\Local\Temp\Hnc\BinData\EMB0000295c17fd.bmp)

​    

홀드아웃 방법의 단점은 성능 추정치가 훈련 데이터 세트를 훈련 및 검증 하위 집합으로 분할하는 방법에 매우 민감할 수 있다는 것입니다. 추정치는 데이터의 다른 예에 따라 다르다.

​    

## K-fold cross-validation

k-fold 교차 검증에서 우리는 훈련 데이터 세트를 교체 없이 k 폴드로 무작위로 나눈다. 여기에서 학습 폴드라고 하는 k – 1 폴드는 모델 학습에 사용되고, 테스트 폴드라는 1 폴드는 성능 평가에 사용된다. 이 절차를 k 번 반복하여 k 모델과 성능 추정치를 얻는다.



그런 다음 홀드아웃 방법과 비교하여 훈련 데이터의 하위 분할에 덜 민감한 성능 추정치를 얻기 위해 서로 다른 독립적인 테스트 폴드를 기반으로 모델의 평균 성능을 계산한다. 

​	-일반적으로 테스트 폴드에 대한 모델 성능 평가에서 추정되는 만족스러운 일반화 성능을 산출하는 최적의 하이퍼파라미터 값을 찾는 모델 튜닝을 위해 k-폴드 교차 검증을 사용한다.



만족스러운 하이퍼파라미터 값을 찾으면 완전한 훈련 데이터 세트에서 모델을 다시 훈련하고 독립적인 테스트 데이터 세트를 사용하여 최종 성능 추정치를 얻을 수 있다. 



k-겹 교차 검증 후 전체 훈련 데이터 세트에 모델을 맞추는 근거

첫째, 일반적으로 단일 최종 모델(k개 개별 모델 대비)에 관심이 있음

두 번째로 학습 알고리즘에 더 많은 훈련 예제를 제공한다는 것입니다. (일반적으로 더 정확하고 강력한 모델이 생성됨)

​	- k-폴드 교차 검증은 교체 없는 리샘플링 기술임

​	-이 접근 방식의 장점은 각 반복에서 각 예제가 정확히 한 번 사용되며 훈련 및 테스트 폴드가 분리됨. 

​	-모든 테스트 폴드는 분리되어 있음

​	-테스트 폴드 간에 겹치는 부분이 없음. 



## Diagnosing bias and variance problems with learning curves

모델이 주어진 훈련 데이터 세트에 대해 너무 복잡한 경우 모델은 훈련 데이터에 과적합되는 경향이 있고 보이지 않는 데이터에 잘 일반화되지 않는다. 

​	-종종 과적합 정도를 줄이기 위해 더 많은 훈련 예제를 수집하는 데 도움이 될 수 있다.



많은 데이터를 수집하는 것이 매우 비용이 많이 들거나 단순히 실현 가능하지 않을 수 있다. 

모델 훈련 및 검증 정확도를 훈련 데이터 세트 크기의 함수로 플로팅함으로써 모델이 고분산 또는 고편향을 겪고 있는지 여부와 더 많은 데이터 수집이 이 문제를 해결하는 데 도움이 될 수 있는지 여부를 쉽게 감지할 수 있다.



## Addressing over- and underfitting with validation curves

검증 곡선은 과적합 또는 과소적합과 같은 문제를 해결하여 모델의 성능을 개선하는 데 유용한 도구다. 검증 곡선은 학습 곡선과 관련이 있지만 훈련 및 테스트 정확도를 샘플 크기의 함수로 표시하는 대신 로지스틱 회귀에서 역 정규화 매개변수 C와 같은 모델 매개변수의 값을 변경합니다.

  ![그림입니다. 원본 그림의 이름: CLP0000295c0038.bmp 원본 그림의 크기: 가로 420pixel, 세로 250pixel](file:///C:\Users\Juns\AppData\Local\Temp\Hnc\BinData\EMB0000295c189a.bmp)  

learning_curve 함수와 유사하게 validation_curve 함수는 기본적으로 계층화된 k-겹 교차 검증을 사용하여 분류기의 성능을 추정한다. 

validation_curve 함수 내에서 평가하려는 매개변수를 지정한다. 이 경우, 우리가 param_range 매개변수를 통해 설정한 지정된 값 범위에 대한 scikit-learn 파이프라인 내부의 LogisticRegression 객체에 액세스하기 위해 'logisticregression__C'로 작성한 LogisticRegression 분류기의 역 정규화 매개변수인 C이다. 



이전 섹션의 학습 곡선 예제와 유사하게 평균 훈련 및 교차 검증 정확도와 해당 표준 편차를 플로팅함.



 다양한 C 값에 대한 정확도의 차이는 미묘하지만 정규화 강도(C의 작은 값)를 높일 때 모델이 데이터에 약간 과소 적합함을 알 수 있습니다. 그러나 C 값이 크면 정규화 강도가 낮아짐을 의미하므로 모델이 데이터에 약간 과적합되는 경향이 있다.





## Tuning hyperparameters via grid search

그리드 검색 접근 방식은 매우 간단하다. 다양한 하이퍼파라미터에 대한 값 목록을 지정하고 컴퓨터가 이 집합에서 최적의 값 조합을 얻기 위해 각 조합에 대한 모델 성능을 평가하는 무차별 대입 완전 검색 패러다임이다.



##  Exploring hyperparameter configurations more widely with randomized search

그리드 검색은 철저한 검색이기 때문에 사용자가 지정한 매개변수 그리드에 포함되어 있으면 최적의 하이퍼파라미터 구성을 찾는 것이 보장된다. 

​	-큰 하이퍼파라미터 그리드를 지정하면 실제로 그리드 검색이 매우 비용이 많이 듭니다. 다른 매개변수 조합을 샘플링하는 다른 방법은 무작위 검색이다. 

​	-무작위 검색에서는 분포(또는 이산 집합)에서 무작위로 초매개변수 구성을 그립니다. 

​	-그리드 검색과 달리 무작위 검색은 하이퍼파라미터 공간에 대한 완전한 검색을 수행하지 않는다. 

​	-비용 및 시간 효율적인 방식으로 더 넓은 범위의 초매개변수 값 설정을 탐색할 수 있습니다. 



## More resource-efficient hyperparameter search with successive halving

  ![그림입니다. 원본 그림의 이름: CLP0000295c0039.bmp 원본 그림의 크기: 가로 508pixel, 세로 211pixel](file:///C:\Users\Juns\AppData\Local\Temp\Hnc\BinData\EMB0000295c18cf.bmp)  

무작위 검색의 아이디어를 한 단계 더 발전시켜 scikit-learn은 적절한 하이퍼파라미터 구성을 보다 효율적으로 찾는 연속적인 반감기 변형인 HalvingRandomSearchCV를 구현한다. 많은 후보 구성 세트가 주어지면 연속 반감기는 하나의 구성만 남을 때까지 유망하지 않은 하이퍼파라미터 구성을 연속적으로 버린다. 



절차 요약

1. 무작위 샘플링을 통해 많은 후보 구성 집합을 그린다.

2. 훈련 데이터의 작은 부분집합과 같이 제한된 리소스로 모델을 훈련합니다.

3. 예측 성능에 따라 하위 50% 폐기한다.

4. 가용 자원을 늘리고 2단계로 돌아간다.



## Algorithm selection with nested cross-validation

 권장 접근 방식은 중첩 교차 검증입니다. 오류 추정의 편향에 대한 훌륭한 연구에서 Sudhir Varma와 Richard Simon은 중첩 교차 검증이 사용될 때 추정의 실제 오류가 테스트 데이터 세트에 비해 거의 편향되지 않는다고 결론지어진다



## Reading a confusion matrix

다양한 채점 지표에 대해 자세히 알아보기 전에 학습 알고리즘의 성능을 나타내는 행렬인 혼동 행렬을 살펴보겠습니다. 혼동 행렬은 그림과 같이 분류기의 참 양성(TP), 참 음성(TN), 거짓 양성(FP) 및 거짓 음성(FN) 예측의 개수를 보고하는 정방형 행렬입니다. 

  ![그림입니다. 원본 그림의 이름: CLP0000295c003a.bmp 원본 그림의 크기: 가로 193pixel, 세로 180pixel](file:///C:\Users\Juns\AppData\Local\Temp\Hnc\BinData\EMB0000295c1938.bmp)  



## Optimizing the precision and recall of a classification model

예측 오차(ERR)와 정확도(ACC)는 모두 얼마나 많은 예가 잘못 분류되었는지에 대한 일반적인 정보를 제공함. 오차는 모든 잘못된 예측의 합을 총 예측 수로 나눈 것으로 이해될 수 있으며 정확도는 각각 올바른 예측의 합을 총 예측 수로 나눈 값으로 계산된다. 예측 오차(ERR)와 정확도 모두 (ACC) 얼마나 많은 예가 잘못 분류되었는지에 대한 일반 정보를 제공합니다. 오류는 모든 잘못된 예측의 합을 총 예측 수로 나눈 것으로 이해될 수 있으며 정확도는 각각 올바른 예측의 합을 총 예측 수로 나눈 값으로 계산됩니다.



## Plotting a receiver operating characteristic

ROC(Receiver Operating Characteristic) 그래프는 분류기의 결정 임계값을 이동하여 계산되는 FPR 및 TPR에 대한 성능을 기반으로 분류할 모델을 선택하는 데 유용한 도구입니다. ROC 그래프의 대각선은 무작위 추측으로 해석될 수 있으며 대각선 아래에 속하는 분류 모델은 무작위 추측보다 나쁜 것으로 간주된다. 

완벽한 분류기는 TPR이 1이고 FPR이 0인 그래프의 왼쪽 상단 모서리에 해당합니다. ROC 곡선을 기반으로 ROC AUC(곡선 아래 면적)를 계산하여 특성화할 수 있다.

ROC 곡선과 유사하게 분류기의 다양한 확률 임계값에 대한 정밀도-재현율 곡선을 계산할 수 있다. 

​    

## Scoring metrics for multiclass classification

지금까지 논의한 스코어링 메트릭은 이진 분류 시스템에만 해당된다. 그러나 scikit-learn은 일대일(OvA) 분류를 통해 이러한 채점 지표를 다중 클래스 문제로 확장하기 위해 매크로 및 마이크로 평균화 방법도 구현한다. 마이크로 평균은 시스템의 개별 TP, TN, FP 및 FN에서 계산된다. 



 k-클래스 시스템에서 정밀도 점수의 미시 평균은 다음과 같이 계산됨

  ![그림입니다. 원본 그림의 이름: CLP0000295c003b.bmp 원본 그림의 크기: 가로 280pixel, 세로 49pixel](file:///C:\Users\Juns\AppData\Local\Temp\Hnc\BinData\EMB0000295c19d5.bmp)  

마이크로 평균화는 각 인스턴스 또는 예측에 동일하게 가중치를 적용하려는 경우에 유용하지만 매크로 평균화는 가장 빈번한 클래스 레이블과 관련하여 분류기의 전체 성능을 평가하기 위해 모든 클래스에 동등하게 가중치를 부여한다.

scikit-learn에서 다중 클래스 분류 모델을 평가하기 위해 이진 성능 메트릭을 사용하는 경우 매크로 평균의 정규화 또는 가중 변형이 기본적으로 사용한다. 가중 거시 평균은 평균을 계산할 때 실제 인스턴스 수에 따라 각 클래스 레이블의 점수에 가중치를 주어 계산한다. 가중 매크로 평균은 클래스 불균형, 즉 각 레이블에 대한 인스턴스 수가 다른 경우에 유용하다.

가중 매크로 평균은 scikit-learn의 다중 클래스 문제에 대한 기본값이지만 sklearn.metrics 모듈에서 가져오는 다양한 스코어링 함수 내부의 평균 매개변수를 통해 평균화 방법을 지정할 수 있다.

## Dealing with class imbalance

불균형 데이터 세트에 도움이 될 수 있는 몇 가지 기술들

357개의 양성 종양(클래스 0)과 212개의 악성 종양(클래스 1)으로 구성된 데이터 세트에서 불균형 데이터 세트를 생성

  ![그림입니다. 원본 그림의 이름: CLP0000295c003c.bmp 원본 그림의 크기: 가로 346pixel, 세로 44pixel](file:///C:\Users\Juns\AppData\Local\Temp\Hnc\BinData\EMB0000295c1a3e.bmp)  

이 코드 조각에서 우리는 357개의 양성 종양 예를 모두 가져와서 처음 40개의 악성 예와 겹쳐서 완전한 클래스 불균형을 만든다.

​	-항상 다수 클래스(양성, 클래스 0)를 예측하는 모델의 정확도를 계산한다면 대략 90%의 예측 정확도를 달성할 것입니다.

![그림입니다. 원본 그림의 이름: CLP0000295c003d.bmp 원본 그림의 크기: 가로 271pixel, 세로 51pixel](file:///C:\Users\Juns\AppData\Local\Temp\Hnc\BinData\EMB0000295c1a3f.bmp)  

 데이터 세트에 분류기를 맞출 때 정밀도, 재현율, ROC 곡선과 같은 다양한 모델을 비교할 때 정확도가 아닌 다른 메트릭에 초점을 맞추는 것이 합리적이다. 

​	-우선 순위는 추가 검사를 권장하기 위해 악성 암을 가진 대다수의 환자를 식별하는 것일 수 있으므로 회상이 우리의 선택 기준이 되어야 합니다. 

기계 학습 모델을 평가하는 것 외에도 클래스 불균형은 모델 피팅 자체 동안 학습 알고리즘에 영향을 미칩니다. 머신 러닝 알고리즘은 일반적으로 피팅 중에 표시되는 훈련 예제에 대해 합으로 계산되는 보상 또는 손실 함수를 최적화하기 때문에 결정 규칙은 다수 클래스로 편향될 가능성이 높다.

​	-즉, 알고리즘은 학습 중 손실을 최소화하거나 보상을 최대화하기 위해 데이터 세트에서 가장 풍부한 클래스를 기반으로 예측을 최적화하는 모델을 암시적으로 학습합니다.

모델 피팅 중 불균형 클래스 비율을 처리하는 한 가지 방법은 소수 클래스에 대한 잘못된 예측에 더 큰 패널티를 할당하는 것입니다. scikit-learn을 통해 이러한 패널티를 조정하는 것은 class_weight 매개변수를 class_weight='balanced'로 설정하는 것만큼 편리하며, 이는 대부분의 분류기에 구현된다.

클래스 불균형을 처리하기 위한 다른 인기 있는 전략에는 소수 클래스 업샘플링, 다수 클래스 다운샘플링 및 합성 훈련 예제 생성이 포함됩니다. 불행히도 다양한 문제 영역에서 가장 잘 작동하는 보편적으로 가장 좋은 솔루션이나 기술은 없다. 

​	-실제로 주어진 문제에 대해 다른 전략을 시도하고 결과를 평가하고 가장 적절해 보이는 기술을 선택하는 것이 좋음



scikit-learn 라이브러리는 교체를 통해 데이터세트에서 새 샘플을 그려 소수 클래스의 업샘플링을 도울 수 있는 간단한 재샘플 기능을 구현한다. 

불균형한 유방암 위스콘신 데이터 세트(여기서는 클래스 1)에서 소수 클래스를 가져와서 클래스 레이블 0과 동일한 수의 예제를 포함할 때까지 반복적으로 새 샘플을 추출합니다.

  ![그림입니다. 원본 그림의 이름: CLP0000295c003e.bmp 원본 그림의 크기: 가로 350pixel, 세로 119pixel](file:///C:\Users\Juns\AppData\Local\Temp\Hnc\BinData\EMB0000295c1a40.bmp)    ![그림입니다. 원본 그림의 이름: CLP0000295c003f.bmp 원본 그림의 크기: 가로 344pixel, 세로 133pixel](file:///C:\Users\Juns\AppData\Local\Temp\Hnc\BinData\EMB0000295c1a41.bmp)  

리샘플링 후 원본 클래스 0 샘플을 업샘플링된 클래스 1 하위 집합과 함께 쌓으면 다음과 같이 균형 잡힌 데이터 세트를 얻을 수 있습니다.

  ![그림입니다. 원본 그림의 이름: CLP0000295c0040.bmp 원본 그림의 크기: 가로 340pixel, 세로 42pixel](file:///C:\Users\Juns\AppData\Local\Temp\Hnc\BinData\EMB0000295c1a42.bmp)  

결과적으로 과반수 투표 예측 규칙은 50%의 정확도만 달성합니다.

​    

마찬가지로 데이터 세트에서 훈련 예제를 제거하여 다수 클래스를 다운샘플링할 수 있습니다. resample 함수를 사용하여 다운샘플링을 수행하려면 이전 코드 예제에서 클래스 1 레이블을 클래스 0으로 간단히 바꾸거나 그 반대로 할 수 있습니다.



