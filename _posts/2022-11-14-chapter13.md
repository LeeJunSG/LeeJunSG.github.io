layout single title: "Chapter 13"


## Going Deeper – The Mechanics of PyTorch

 PyTorch API의 다양한 측면을 사용하여 NN을 구현한다. 특히, 표준 아키텍처의 구현을 매우 편리하게 만들기 위해 다중 추상화 계층을 제공하는 torch.nn 모듈을 다시 사용한다. 또한 더 많은 사용자 정의가 필요한 연구 중심 프로젝트에 매우 유용한 사용자 정의 NN 레이어를 구현할 수 있다. 
torch.nn 모듈을 사용하여 모델을 구축하는 다양한 방법을 설명하기 위해 고전적인 배타적 또는 (XOR) 문제도 고려한다. 먼저 Sequential 클래스를 사용하여 다층 퍼셉트론을 빌드한다. 그런 다음 사용자 정의 레이어를 정의하기 위해 nn.Module을 서브클래싱하는 것과 같은 다른 방법을 고려한다. 마지막으로 원시 입력에서 예측에 이르는 기계 학습 단계를 다루는 두 가지 실제 프로젝트에서 작업할 것이다.

이를 다음과 같은 과제로 나눌 수 있다.

- PyTorch 계산 그래프 이해 및 작업
- PyTorch 텐서 객체 작업
- 고전적인 XOR 문제 해결 및 모델 용량 이해
- PyTorch의 Sequential 클래스와 nn.Module 클래스를 사용하여 복잡한 NN 모델 구축
- 자동 미분 및 torch.autograd를 사용하여 그라디언트 계산

### The key features of PyTorch

 동적 계산 그래프를 사용하므로 정적 그래프에 비해 더 유연하다는 장점이 있다. 동적 계산 그래프는 디버깅 친화적이다. PyTorch는 그래프 선언 및 그래프 평가 단계를 인터리빙할 수 있다. 모든 변수에 대한 전체 액세스 권한을 가지면서 코드를 한 줄씩 실행할 수 있다. 이것은 NN의 개발과 훈련을 매우 편리하게 만드는 매우 중요한 기능이다.



### Understanding computation graphs

PyTorch는 핵심에서 계산 그래프를 구축하는 데 의존하며 이 계산 그래프를 사용하여 입력에서 출력까지 텐서 간의 관계를 도출한다. 순위 0(스칼라) 텐서 a, b, c가 있고 z = 2 × (a – b) + c를 평가하려고 한다고 가정했을 때, 다음과 갔은 그래프로 표시할 수 있습니다.

![그림](/image/image-20221113043711481.png)

### PyTorch tensor objects for storing and updating model parameters

12장, PyTorch로 신경망 훈련 병렬화에서 텐서 객체를 다루었습니다. PyTorch에서 그라디언트를 계산해야 하는 특수 텐서 객체를 사용하면 훈련 중에 모델의 매개변수를 저장하고 업데이트할 수 있다. 이러한 텐서는 사용자가 지정한 초기 값에 대해 requires_grad를 True로 지정하기만 하면 생성할 수 있다. 현재(2021년 중반) 현재 부동 소수점 및 복소수 dtype의 텐서만 그라디언트가 필요할 수 있다.

### Computing gradients via automatic differentiation

PyTorch는 중첩 함수의 기울기를 계산하기 위한 연쇄 규칙의 구현으로 생각할 수 있는 자동 미분을 지원한다. 단순함을 위해 기울기라는 용어를 편미분과 기울기를 모두 참조하는 데 사용할 것이다.



### Computing the gradients of the loss with respect to trainable variables

자동 미분은 임의의 산술 연산의 기울기를 계산하기 위한 일련의 계산 기술을 나타낸다. 이 과정에서 일련의 연산으로 표현되는 연산의 기울기는 연쇄법칙을 반복적으로 적용하여 기울기를 누적하여 구한다. 자동 미분의 개념을 더 잘 이해하기 위해 입력 x와 출력 y가 있는 일련의 중첩 계산 y = f(g(h(x)))를 고려가 가능하다.



### Implementing models based on nn.Sequential

nn.Sequential(https://pytorch.org/docs/master/generated/torch.nn.Sequential.html#sequential)을 사용하면 모델 내부에 저장된 레이어가 계단식으로 연결됩니다. 다음 예제에서는 두 개의 조밀하게(완전히) 연결된 레이어가 있는 모델을 만들 것입니다. 레이어를 지정하고 nn.Sequential 클래스에 레이어를 전달한 후 모델을 인스턴스화한다. 

- 첫 번째 완전 연결 계층의 출력은 첫 번째 ReLU 계층의 입력으로 사용된다. 

- 첫 번째 ReLU 계층의 출력은 두 번째 완전 연결 계층의 입력이 된다. 

- 마지막으로 두 번째 완전 연결 계층의 출력이 두 번째 ReLU 계층의 입력으로 사용된다.
  예를 들어 다른 활성화 함수, 초기화 또는 정규화 방법을 매개변수에 적용하여 이러한 계층을 추가로 구성할 수 있다.

* 구현할 손실 텐서에 L1 페널티 항을 추가하여 계층 매개변수에 L1 정규화를 적용한다(과적합 방지). 가중치에 대한 초기 값 분포를 지정하여 첫 번째 완전 연결 계층을 구성한다. 그런 다음 가중치 행렬에 대한 L1 페널티 항을 계산하여 두 번째 완전 연결 계층을 구성한다.

###  Choosing a loss function

최적화 알고리즘의 선택과 관련하여 SGD와 Adam이 가장 널리 사용되는 방법이다. 손실 함수의 선택은 작업에 따라 다릅니다. 예를 들어 회귀 문제에 평균 제곱 오차 손실을 사용할 수 있다.
교차 엔트로피 손실 함수 제품군은 14장, 심층 컨볼루션 신경망으로 이미지 분류에서 광범위하게 논의되는 분류 작업에 대한 가능한 선택을 제공한다.

### Solving an XOR classification problem

XOR 분류 문제는 두 클래스 간의 비선형 결정 경계를 캡처하는 것과 관련하여 모델의 용량을 분석하기 위한 고전적인 문제이다. [–1, 1) 사이의 균일한 분포에서 추출한 두 개의 특징(x0, x1)이 있는 200개의 훈련 예제의 장난감 데이터 세트를 생성한다. 그런 다음 다음 규칙에 따라 훈련 예제 i에 대한 정답 레이블을 할당한다. 이를 통해 다음과 같은 훈련 및 검증의 산점도를 생성할 수 있다.

![그림](/image/image-20221113055536054.png)



### Making model building more flexible with nn.Module

 PyTorch Sequential 클래스를 사용하여 여러 레이어로 완전히 연결된 NN을 생성할 수 있다. 이것은 모델을 구축하는 매우 일반적이고 편리한 방법이다. 그러나 불행히도 다중 입력, 출력 또는 중간 분기가 있는 더 복잡한 모델을 만들 수 없다. 
복잡한 모델을 빌드하는 다른 방법은 nn.Module을 서브클래싱하는 것이다. 이 접근 방식에서는 nn.Module에서 파생된 새 클래스를 만들고 __init__() 메서드를 생성자로 정의합니다. forward() 메서드는 정방향 패스를 지정하는 데 사용된다. 생성자 함수 __init__()에서 계층을 클래스의 속성으로 정의하여 자체 참조 속성을 통해 액세스할 수 있도록 한다. 그런 다음 forward() 메서드에서 이러한 레이어가 NN의 순방향 패스에서 사용되는 방법을 지정한다. 이전 모델을 구현하여 그래프로 나타내면 다음과 같다.

![그림](/image/image-20221113055643044.png)

또한, PyTorch에서 아직 지원하지 않는 새 레이어를 정의하려는 경우 nn.Module 클래스에서 파생된 새 클래스를 정의할 수 있다. 이는 새 레이어를 디자인하거나 기존 레이어를 사용자 지정할 때 특히 유용하다.
 이 새 클래스의 경우 생성자 __init__() 메서드와 forward() 메서드를 모두 정의해야 한다. 생성자에서 우리는 사용자 정의된 레이어에 대한 변수 및 기타 필수 텐서를 정의한다. input_size가 생성자에 주어지면 변수를 생성하고 생성자에서 초기화할 수 있다. 또는 변수 초기화를 지연하고 나중에 변수 생성을 위해 다른 메서드에 위임할 수 있다.
이를 그림으로 나타내면 다음과 같다.

![그림](/image/image-20221113055713847.png)



### Working with feature columns



기계 학습 및 딥 러닝 응용 프로그램에서 연속, 정렬되지 않은 범주형(명목형) 및 정렬된 범주형(서수형)과 같은 다양한 유형의 기능을 만날 수 있다. 경우에 따라 기능 세트는 다양한 기능 유형이 혼합되어 구성된다. 다음과 같이 7개의 다른 기능 세트가 있는 시나리오를 고려된다.

![그림](/image/image-20221113055746306.png)



### Setting up the data loaders for Lightning

Lightning용 데이터 세트를 준비할 수 있는 세 가지 주요 방법이 있다.

- 데이터세트를 모델의 일부로 만듭니다.
- 데이터 로더를 평소와 같이 설정하고 Lightning Trainer의 적합 방법에 공급합니다. 
- LightningDataModule 생성
  
  

### Training the model using the PyTorch Lightning Trainer class

이제 특별히 명명된 메서드와 Lightning 데이터 모듈로 모델을 설정하여 보상을 얻을 수 있다. Lightning은 zero_grad(), backward() 및 optimizer.step() 호출과 같은 모든 중간 단계를 처리하여 교육 모델을 매우 편리하게 만드는 Trainer 클래스를 구현한다. 또한 보너스로 사용할 하나 이상의 GPU를 쉽게 지정할 수 있다(사용 가능한 경우). 또한 Lightning의 또 다른 좋은 기능은 로깅 기능이다. 훈련 후, 심지어 훈련 중에도 TensorBoard에서 시각화할 수 있다. 

